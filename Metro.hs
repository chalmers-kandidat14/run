{-# LANGUAGE RankNTypes #-}
module Metro (
               Candidate (..)
             , metropolisHastings
             , pick
             ) where

import System.Random.MWC --This requires that the mwc-random
import Debug.Trace
import Control.Monad
import Control.Monad.Primitive

-- A datatype that is used to store the current state of the evaluation of the 
-- Metropolis Hastings algorithm.
--
--   * currentState is the most resent state in the markov chain generated by
--     the algorithm
--
--   * currentValue is the value of the current state.
--
--   * accepts is the number of accepted state transition so far in the algorithm
data MarkovChain s = MarkovChain { currentState :: s
                                 , currentValue :: Double
                                 , accepts      :: Int
                                 }

-- A datatype that stores the candidate state and related data that is used by
-- the Metropolis Hastings algorithm.
--
--   * candidate is the proposed next state in the markov chain that is being
--     generated by the algorithm
--
--   * probabilities is the probabilities of going from the current state to
--     the candidate state and the probability of going from the candidate
--     state to current state.
data Candidate s = Candidate { candidate     :: s
                             , probabilities :: (Double, Double)
                             }

-- Select one element at random from a list
pick :: (PrimMonad m) => [a] -> Gen (PrimState m) -> m a
pick xs gen = uniformR (0, (length xs)-1) gen >>= return . (xs!!)

-- The type of the scoring function.
type Pi s = s -> Double

-- The type of the candidate generating function.
type Q m s = s -> Gen (PrimState m) -> m (Candidate s)


mHStep :: PrimMonad m       =>
          Pi s              -> -- The scoring function 
          Q m s             -> -- The candidate generating function
          MarkovChain s     -> -- The current state of the markov chain
          Double            -> -- The current temperature
          Gen (PrimState m) -> 
          m (MarkovChain s)
mHStep pi q state t g = do
  let (x, px, acpts) = (currentState state, currentValue state, accepts state)
  (Candidate y (qxy, qyx)) <- q x g
  let py = pi y
  let a = min 1.0 $ exp (((qyx * py) - (qxy * px)) / t)
  u <- uniformR (0.0, 1.0) g
  if u <= a
    then return $ MarkovChain y py (acpts + 1)
    else return state


metropolisHastings :: (PrimMonad m) =>
                   Pi s ->
                   Q m s ->
                   s ->
                   Gen (PrimState m) ->
                   [Double] ->
                   m (s, Int)
metropolisHastings p q ch gen (t:temps) = returnValue $ foldM f start temps
    where
        returnValue result = do
                            MarkovChain ch _ acc <- result
                            return (ch, acc)
        start = MarkovChain ch (p ch) 0
        f current temp = mHStep p q current temp gen
